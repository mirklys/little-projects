{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNL/IDr6I6eEk0PL0TS9aY1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirklys/little-projects/blob/main/thesis/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install Box2D\n",
        "!pip3 install box2d-py\n",
        "!pip3 install gym[all]\n",
        "!pip3 install gym[Box_2D]"
      ],
      "metadata": {
        "id": "WMZs7R9ZI3rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines\n",
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "id": "7S4-NTFWI9uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "j0eb_a4oI_Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import os\n",
        "import numpy as np\n",
        "import torch as th\n",
        "from torch import nn\n",
        "from torch.distributions.bernoulli import Bernoulli\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.utils import get_device\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines.common import set_global_seeds, make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor"
      ],
      "metadata": {
        "id": "CBYOOEBRJAgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ubm27tJFfZ",
        "outputId": "26430829-1db8-4e7b-8567-101da7d0ea27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_BASE = '/content/gdrive/MyDrive/Thesis Project'\n",
        "PATH_DATA = os.path.join(PATH_BASE, 'data/')\n",
        "PATH_NETWORKS = os.path.join(PATH_BASE, 'networks/')\n",
        "PATH_PLOTS = os.path.join(PATH_BASE, 'plots/')\n",
        "PATH_RESULTS = os.path.join(PATH_BASE, 'results/')\n",
        "PATH_LOGS = os.path.join(PATH_BASE, 'logs/')\n",
        "os.chdir(PATH_BASE)"
      ],
      "metadata": {
        "id": "x80V7H8yJHSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_network(game:str, size:int, dropout:float) -> str:\n",
        "    title = \"{}.{}x{}.dropout_{}\".format(game, size, size, dropout)\n",
        "    env = make_vec_env(game, n_envs=10, seed=0, vec_env_cls=DummyVecEnv)\n",
        "    model = PPO.load(os.path.join(PATH_NETWORKS, game, title))\n",
        "\n",
        "    rew, std = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "\n",
        "    return \"Networks cumulative reward {:.2f} ±{:.2f}\".format(rew, std)"
      ],
      "metadata": {
        "id": "1x6q_2jGJKgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_network('BipedalWalker-v3', 128, 0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "bP7DFzUEKn_O",
        "outputId": "2e761781-eafa-4a23-b4b6-afa280fee8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Networks cumulative reward 317.78 ±0.60'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_network('BipedalWalker-v3', 128, 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Y2J8WaTmK0d-",
        "outputId": "fee1adc9-028b-44b6-d6a6-c51fc6cf2352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Networks cumulative reward 200.50 ±135.86'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}